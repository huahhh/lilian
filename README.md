# lilian documentation

## 1. 基础环境及其依赖

### 1.1 运行环境

该爬虫框架使用python开发，拥有python环境的跨平台性，核心代码及其python依赖兼容
python2&python3

<br/>

### 1.2 外部依赖

#### 1.2.1 种子队列（seed queue）

需依赖一个种子队列服务来实现爬虫的，分布式，请求无状态，请求隔离，种子管理。
现行使用的是基于level DB封装的ssdb，该服务兼容redis接口，数据落盘于hardDisk，性
能在测试中并不弱于redis。
亦可使用更具有普适性的redis（实际上初期一直使用的是redis，但redis会给内存资源造成
很大的压力，故改为ssdb）
亦或是，实现queue的其他服务，但至少需自行实现q_pop & q_push两个关键接口。

<br/>

#### 1.2.2 去重集合（set）

需依赖一个去重集合来实现爬虫的请求去重，以及各种逻辑去重。
现行使用ssdb的zset实现。经测试，单队列在count < 5亿 的情况下的性能仍能满足业务需
求
亦可使用boolm filter来实现。

<br/>

#### 1.2.3 监控

需依赖一个数据集合来实现爬虫的采集数据量监控计数。
现行使用ssdb的hash实现

<br/>

#### 1.2.4 logstash（or kafka & mongoDB）

数据结果集流向kafka（对接后续清洗）& mongoDB（数据冷备）
现行使用logstash作为数据传输枢纽。
亦可直接写入 kafka & mongoDB

<br/>

#### 1.2.5 python第三方库依赖

详见附录 requirements.txt

<br/>

## 2. 设计思路

### 2.1 进程独立

在框架的基础设计里，爬虫运行的最小单元为一个进程，该单独的进程拥有独立的各DB链接，独立
的Downloader， 独立的proxy链接等。一个爬虫可能有多个进程（至少有一个）。每个进程之间互
不影响。

<br/>

### 2.2 请求独立

爬虫的每个http请求是独立的，框架会把每个requests请求封装为一个格式为可被json化的dict的种
子对象。在设计上，种子与进程隔离，进程通过消耗初始种子（初始url）根据爬虫逻辑生成更多的
种子并push到种子队列，进程再从种子队列pop出种子进行请求与解析（多进程模型下，处理种子
的可能就不是同一个进程了，这里就体现了请求与进程分离，请求是独立的。）

<br/>

### 2.3 种子队列

在设计上，种子队列是实现框架，分布式，并行化，无状态化的基础
种子队列本质上是一个先入后出队列。

<br/>

### 2.4 配置化

在设计上，尽力将编码过程中可能会存在改变的常量项抽离出来，形成配置配置文件，方便后期调
整。
现在的配置化实现是以ini文件的形式，在框架中封装有get_config接口，需要读取配置的地方通过
该接口获取某项配置。
后期规划上，此处会考虑升级为配置服务，以便实现配置的集中化管理，对各模块的热修改以及热
更新。

<br/>

### 2.5 模块化

将爬虫的请求，DB链接，监控，代理，配置，种子管理等抽象为单独的模块，得以解耦合，方便单
独管理升级。

<br/>

### 2.6 进程管理

使用python有名的进程管理库supervisor进行进程守护，监控，以及管理。
通过supervisor的xmlrpc对外开放管理接口，用以增减进程，读取log等。

<br/>

## 3. 模块化分析

### 3.1 DB

使用工厂模式封装对各个DB库的链接（redis， ssdb， mongo等）
通过dblibs下的db_provide做为统一的接口，通过传参（实际启动可能是通过读配置的形式）生成
各DB的实例供单个爬虫调用

<br/>

### 3.2 Downloader

封装requests库，增加爬虫对正常response的判断，对代理的应用， 对请求失败的重试， 对
headers & cookies的定制， 等逻辑

<br/>

### 3.3 middlewares

分为requests_middleware和response_middleware（此处借鉴scarpy的设计）

> **requests_middlleware **: 爬虫发起的请求在被请求之前都会通过requests_middleware，用
以做hook操作。框架默认增加的requests_middleware为check_seed_middleware，该
middleware用以对seed_json做基本的检查以及生成seed对象

> **response_middleware **: 爬虫发起请求之后，经Downloader返回的response对象会通过所
有的response_middleware再传回spider。框架默认的有，check_html_middleware ,
check_status_code_middleware, html_encoding_middleware
>
> > ***check_html_middleware ***: 通过爬虫配置，根据通过middleware的response的text
文本的某些关键字来判断返回的页面是否正确，若不正确则重试。（若超出重试限
制，则写入error_html队列）
***check_status_code_middleware***: 通过爬虫配置，根据通过middleware的response
的http_status_code来判断是否是正常的response，若不正确则重试。（若超出重
试限制，则写入error队列）
***html_encoding_middleware***: 通过自动判断编码，来对response的text进行编码，
主要是解决源网站网页乱码的问题

开发者亦可以开发自己需要的middleware，放在middleware目录下，并通过爬虫类的
self.spider_request_middleware or self.spider_response_middleware使用即可。

<br/>

### 3.4 monitor

现行的monitor为挂在spider_base下的一个模块。主要用作对爬虫进程的各个关键信息的监控，监
控的表现形式为主动式和被动式。

> **主动式**: 爬虫进程主动往ssdb的hash推送数据。主要用作爬虫的每日采集监控， 当爬虫正
确采集入库一条数据时， hash里该爬虫的当日key的value+1，爬虫数据量监控从ssdb的
hash读取监控数据， 用以展示每日抓取数据量情况。

> **被动式**: 爬虫进程被动的从ssdb读取ssdb队列的一些信息。包括待抓取队列大小， error队
列大小， error_html队列大小等数据。后加上本身内存持有的，处理过各类parser_func的
seed数计数，返回的response的status_code计数。在每次抓取完毕的最后以log的形式展
示出来。

<br/>

### 3.5 proxy

proxyinterface主要是对代理服务的client的封装。（对应的proxy_server实际上是对代理供应商的
封装）
现行的proxyinterface，为简单的读取代理服务配置，通过http请求一个由go封装的代理服务取得代
理。具体的代理调度逻辑由代理服务负责。该模块只负责取得代理并返回给Downloader（故该模块
的实例由Downloader持有）
该模块对外开放的仅get_proxy这个实例方法。

<br/>

### 3.6 seed

seed模块实际上是对http request & response对象的软性封装，主要使request对象json化，并适应
框架逻辑。另外，再加上一些常用的操作性方法。
爬虫实例从seed队列pop出一个seed（此时是一个符合json语法的字符串），经过检验，load ，等
操作后将seed对象传入Downloader执行网络请求。完成后，返回response（实际上是原seed对
象。）后由爬虫处理（传入seed对应的parser_func），以生成更多seed或是生成结果数据。

<br/>

### 3.7 config

config模块实际上对配置封装，为各处需要读取的配置提供统一的接口，并统一调用。
现行的config模块的配置实体实际上是一个个ini文件。
配置模块的封装实际上还是非常简陋的。只提供了对配置项统一读取的接口。但是一些常用功能
（动态刷新，版本控制等）并没有实现。故，可能后期考虑使用配置服务来替换该模块。

<br/>

### 3.8 commonlib + tools

这两个模块实际上是这两个目录下的多个模块的统称。

>  **commonlib**: 该目录存放框架会用到的一些公共库，如单例类（single class），日志类
（logger class）， 重试类（retry class）

> **tools**: 该目录存放爬虫会用到的一些公共库。

<br/>

### 3.9 manager

manager是个重要的模块，主要是对整个框架一些通用管理方法的封装。

> ** 生成配置**: 现行爬虫并发配置为（spider_name = process_num），需要通过该配置生成
supervisor可用的配置。（即读取spider_config.ini生成spider_run.ini）

>  **灌入初始种子**: 爬虫第一次上线的时候需要灌入初始种子。通过调用该方法实现。

>  **清空爬虫队列**: 清空爬虫的所有队列信息（包括种子队列，monitor队列，去重队列等），
用于爬虫的从头抓取（重置爬虫）

> **定时灌种**: 定时灌入爬虫的初始种子（相当于定时启动爬虫抓取）

<br/>

## 架构图

<br/>

### 4.1 整体框架结构图

![spider_framework.png](https://s2.loli.net/2022/03/17/xQZAYe5kNanpK8v.png)

<br/>

### 4.2 爬虫运行流程图

![spider_single.png](https://s2.loli.net/2022/03/17/8ERSHUo9FiPawnx.png)

<br/>

## 5. 性能评测

### 5.1 测试环境

> CPU: E5-2670 *2 (2.3Ghz, 12C24T )
RAM: 128G
DISK: HDD
PYTHON: 3.7

<br/>

### 5.2 资源消耗

启动爬虫，灌入初始种子后，待爬虫稳定运行30min后，在一定时间内观测进程监控信息。

<br/>

#### 5.2.1 cpu消耗

> 基准测试中，稳定运行消耗大概在单核的3% ~ 6%左右
抓取过程中会根据html大小瞬态达到单核的10% ~ 40%（主要是生成html的etree对象）
进程静止休眠时（监控seed队列，等待抓取）在单核的1%以下
如若请求到某些特别大的html（5M以上），或文件性地址（exe or rar）对cpu的占用会短
暂的达到100%

<br/>

#### 5.2.2 内存消耗

> 基准测试中，稳定运行消耗大概在70M左右
爬虫进程在某情况下尚有内存泄漏的风险（请求的html大于5M），经查，基本定位在lxml
这个库的问题。在使用该库进行html解析时，会产生html_etree对象不释放的风险。该情况
暂时没有很好的解决方案，现行的解决方案为使用supervisor的插件，当进程内存消耗>300M时便强制停止进程并重启

<br/>

### 5.3 单进程测试

运行单个爬虫进程，观察log。有一下结论

> 单个种子（即单个请求）的处理时间大概在0.3s ~ 1.0s（包括取出种子，正常请求，解析
处理入库）
单进程的日平均抓取量大约为6W左右（2个请求得到1条结果数据）（该测试结果包含了因
代理，反爬造成的重试的效率损耗）
>
> > *注 : 上述测试的目标网站的响应情况非常良好，若对方网站的数据返回质量很差，
以上测试数据会有较大波动。*

<br/>

### 5.4 框架整体测试

于上述配置服务器运行框架。测试进程为1000个（需错峰启动，同时启动会瞬间吃光cpu并死机）
经30min观察，框架稳定运行，但cpu & ram 资源基本吃空
经一段时间统计，数据量单日峰值可达4KW左右，均值2KW（此处为结果数据）

> 抓取网站为天*查，若受网站响应时间与响应率影响，可能会有不小的差别

> 取得一条结果数据的请求量为2， 故整体请求量大概在日峰值8KW，日均值4KW

<br/>

## 6. 后续规划

### 6.1  配置中心化

基于能够动态的修改爬虫进程运行过程中的一些关键性配置的需求，后期规划上，会引入配置中心
服务，并将config模块重新封装用以对接配置中心。
包括但不仅限于一下配置项

> spider_name级别的进程数量的配置，期望达到，前端页面修改配置，后台manager即时调
整爬虫进程，以此达到修改抓取效率的需求

> 各DB的配置，在某些情况下，会有动态的修改爬虫的各DB的链接的需求。

> 框架本身的一些配置， 包括log输出配置， 种子队列配置， 管道配置， 代理服务配置等

<br/>

### 6.2 持续集成

基于节省日常运维成本，减少重复性工作这样的需求。后期规划上，会引入框架的持续集成机制。
做到修改后实时发布。

<br/>

框架的持续集成在规划上会基于git，以及对git的多分支的应用
设计上，框架代码有**master**， **release**， **other dev**(个人开发)三个主要分支

<br/>

***master***: 框架的主要分支，禁止直接commit代码到该分支，修改分支代码仅可通过merge的形式，
原则上仅支持从release分支merge到master分支。持续集成服务会监控该分支，若分支有任何修改
（即版本往前走了一个版本），会自动拉取该分支的最新代码，重新构建爬虫服务。

<br/>

***release***:框架的预上线分支，原则上，该分支不接受直接commit代码，仅支持从other dev分支
merge到该分支。该分支为对接集成测试的分支，若开发过程中存在正规的测试环节，可从该分支
拉取代码进行测试。该分支代码测试通过后，会定期的merge到master分支（实际上，这就是一个
稳定的上线流程）

<br/>

***other dev***: 框架的个人开发分支，由各协助者push到origin， 各协作开发者可根据开发需要，在保
证线上分支尽量清洁的情况下可push若干个人开发分支至origin。个人开发分支有如下要求

<br/>

- push到origin之前需要通过自测。
- 使用完线上个人分支后（已merge到release 或废弃），需删除该分支。
- 需注意个人分支之间可能产生的代码冲突。

  在持续集成的规划中，会考虑使用docker封装爬虫框架，并以xmlrpc的方式，对外开放管理接口，

以此使部署框架的工作与运维的工作剥离开来，且使得框架的可视化管理得以方便的实现。

<br/>

### 6.3  可视化管理

基于直观的观察爬虫的运行情况与抓取情况，以及将爬虫服务的各个模块，环节集成在同一个可视
化界面中。后期规划上考虑自行研发爬虫服务的可视化管理后台。至此，爬虫框架这块儿可以说已
经是一个较为完备的系统，一个可以对外提供数据引擎作用的产品了。
将爬虫框架封装为一个可视化爬虫管理系统的前提是将爬虫框架容器化（使用docker容器是容器化
的一种实现方式，建议使用docker，但不仅限于docker）。目的是将爬虫服务，与爬虫管理剥离开
来，解耦服务之间的依赖关系。两服务之间可以通过http，或xmlrpc， 或jsonrpc实现，通信协议这
块儿已有成熟的方案。

<br/>

---
